# Server Configuration
HOST=0.0.0.0
PORT=8002
PROTOCOL=JSONRPC

# LLM Model Configuration
AGENT_MODEL=gemini/gemini-2.0-flash-exp
AGENT_API_BASE=http://localhost:4444
AGENT_API_KEY=your-litellm-api-key

# Confluence MCP Server Configuration
# Uses streamable-http (SSE) connection to MCP server
CONFLUENCE_MCP_SERVER_URL=http://localhost:3000/mcp

# Agent Behavior Configuration
MAX_SEARCH_RESULTS=5
CITATION_REQUIRED=true
USE_REASONING=true
